# -*- coding: utf-8 -*-
"""KNN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1e9idstCx-sI2HnJwiv-nGffhtFYmDoCt

#### Importando bibliotecas
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import scipy as scp
import warnings
warnings.filterwarnings("ignore")

"""#### Dataset"""

cog_df = pd.read_csv("mushrooms.csv", engine ="python", sep=",")
cog_df.head()

cog_df.info()

cog_df.describe()

def distribuicao(data):
  num_unique_labels = data.apply(pd.Series.nunique)
  num_unique_labels.plot(kind="bar")
  plt.xlabel('Campos')
  plt.ylabel('Número de registros únicos')
  plt.title('Distribuição de dados únicos no dataset')
  plt.show()

distribuicao(cog_df)

e = pd.value_counts(cog_df['class']) [0] #edible:comestível
p = pd.value_counts(cog_df['class']) [1] #poisonous: venenoso

print('Cogumelos Comestíveis: ',e)
print('Cogumelos Venenosos: ',p )

classes = pd.DataFrame([['Comestível',e],['Venenoso',p]],
                   columns=['Tipo' , 'Quantidade'])

classes

def pie_chart(data,col1,col2,title): 
    labels = {'Comestível':0,'Venenoso':1}
    sizes = data[col2]
    colors = ['#03989E', '#E63751']

    plt.pie(sizes, labels=labels, colors=colors,
                autopct='%1.1f%%', shadow=True, startangle=140, 
            labeldistance =1.2)
    plt.title( title )
    
    plt.axis('equal')
    plt.show()

pie_chart(classes,'Tipo' , 'Quantidade',
          'Distribuição Percentual Classes de Cogumelos')

plt.bar(classes.Tipo,classes.Quantidade, 
        color = ['#03989E', '#E63751'])
plt.title("Distribuição das Classes de Cogumelos")
plt.xlabel("Tipo de Cogumelo")
plt.ylabel('Quantidade de Registros')
plt.show()



"""## Split do dataset"""

# X =  colunas de informação, variáveis independentes
X = cog_df.drop('class', axis=1)
# y = Variável dependente (para classificar os dados)
y = cog_df['class']
# Verificando se X está com a coluna class 
X.head()

# Verificando se X está com a coluna class 
X.head()

"""## Transformando labels em números"""

from sklearn.preprocessing import OneHotEncoder
Oht_enc = OneHotEncoder()
X = pd.DataFrame(Oht_enc.fit_transform(X).A)

X.head()

"""## Treino e teste"""

from sklearn.model_selection import train_test_split 
X_train,X_test,y_train,y_test = train_test_split(X,y, test_size=0.3)

"""## Redução de escalas das colunas"""

from sklearn.preprocessing import StandardScaler  
scaler = StandardScaler()  
scaler.fit(X_train)

X_train = scaler.transform(X_train)  
X_test = scaler.transform(X_test)

"""## Criação do modelo KNN"""

from sklearn.neighbors import KNeighborsClassifier  

#Definindo K
classifier = KNeighborsClassifier(n_neighbors=5)  
#Treinamento do modelo (dados de treinamento)
classifier.fit(X_train, y_train)

#Previsão dos valores de Y para os dados de teste (X_test)
y_pred = classifier.predict(X_test)

"""## Avaliação do algoritmo"""

# Importando métricas para validação do modelo
from sklearn.metrics import classification_report, confusion_matrix, \
accuracy_score

# Imprimindo a matriz confusa
print("Matriz Confusa: ")
print(confusion_matrix(y_test, y_pred), "\n")  

# Imprimindo o relatório de classificação
print("Relatório de classificação: \n", classification_report(y_test, y_pred))  

# Imprimindo o quão acurado foi o modelo
print('Acurácia do modelo: ' , accuracy_score(y_test, y_pred))

"""## Testando valores de K"""

error = []

# Calculando o erro para valores entre 1 e 10
for i in range(1, 10):  
    knn = KNeighborsClassifier(n_neighbors=i)
    knn.fit(X_train, y_train)
    pred_i = knn.predict(X_test)
    error.append(np.mean(pred_i != y_test))

error

"""## Comparação do Erro Rate"""

plt.figure(figsize=(12, 6))  
plt.plot(range(1, 10), error, color='red', 
         linestyle='dashed', marker='o',  
         markerfacecolor='blue', markersize=10)
plt.title('Error Rate K Value')  
plt.xlabel('K Value')  
plt.ylabel('Mean Error')

"""## Aplicação do melhor parâmetro para K encontrado"""

#Treinando o modelo KNN com o melhor parâmetro para K
from sklearn.neighbors import KNeighborsClassifier  
classifier = KNeighborsClassifier(n_neighbors=1)  
classifier.fit(X_train, y_train)

#Aplicando os valores de teste novamente
y_pred = classifier.predict(X_test)

# Importando métricas para validação do modelo
from sklearn.metrics import classification_report, confusion_matrix,\
 accuracy_score

# Imprimindo a matriz confusa
print("Matriz Confusa: ")
print(confusion_matrix(y_test, y_pred), "\n")  

# Imprimindo o relatório de classificação
print("Relatório de classificação: \n", classification_report(y_test, y_pred))  

# Imprimindo o quão acurado foi o modelo
print('Acurácia do modelo: ' , accuracy_score(y_test, y_pred))